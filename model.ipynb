{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haZAR\\anaconda3\\envs\\pytorchgpu\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ListSkip(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(ListSkip , self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv1d = nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, stride=4, padding=1)\n",
    "        self.conv1dd = nn.Conv2d(in_channels=64, out_channels=512, kernel_size=3, stride=8, padding=1)\n",
    "        self.conv2d = nn.Conv2d(in_channels=128, out_channels=512, kernel_size=3, stride=4, padding=1)\n",
    "\n",
    "    def add_skip(self, skip_list):\n",
    "        el1 = skip_list[0]\n",
    "        el2 = skip_list[1]\n",
    "        el3 = skip_list[2]\n",
    "        el4 = skip_list[3]\n",
    "        el1_conv = self.conv1(el1)\n",
    "        el1_convd = self.conv1d(el1)\n",
    "        el1_convdd = self.conv1dd(el1)\n",
    "        el2_conv = self.conv2(el2)\n",
    "        el2_conv2d = self.conv2d(el2)\n",
    "        el3_conv = self.conv3(el3)\n",
    "\n",
    "        skip_new = [el1 , el1_conv+el2 , el1_convd+el2_conv + el3 ,el1_convdd+el2_conv2d+el3_conv+el4]\n",
    "        return skip_new\n",
    "    def forward(self,x):\n",
    "        return self.add_skip(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torchvision.transforms.functional as TF\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class ListSkip(nn.Module):\n",
    "#     def __init__(self,):\n",
    "#         super(ListSkip , self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2, padding=1)\n",
    "#         self.conv3 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=2, padding=1)\n",
    "#         self.conv1d = nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, stride=4, padding=1)\n",
    "#         self.conv1dd = nn.Conv2d(in_channels=64, out_channels=512, kernel_size=3, stride=8, padding=1)\n",
    "#         self.conv2d = nn.Conv2d(in_channels=128, out_channels=512, kernel_size=3, stride=4, padding=1)\n",
    "\n",
    "#     def add_skip(self, skip_list):\n",
    "#         el1 = skip_list[0]\n",
    "#         el2 = skip_list[1]\n",
    "#         el3 = skip_list[2]\n",
    "#         el4 = skip_list[3]\n",
    "#         # convel1_el2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=1)\n",
    "#         # convel2_el3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2, padding=1)\n",
    "#         # convel3_el4 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=2, padding=1)\n",
    "#         el1_conv = self.conv1(el1)\n",
    "#         el1_convd = self.conv1d(el1)\n",
    "#         el1_convdd = self.conv1dd(el1)\n",
    "     \n",
    "\n",
    "#         el2_conv = self.conv2(el2)\n",
    "#         el2_conv2d = self.conv2d(el2)\n",
    "\n",
    "\n",
    "#         el3_conv = self.conv3(el3)\n",
    "\n",
    "\n",
    "#         skip_new = [el1 , torch.mul(el1_conv,el2) , torch.mul(el2_conv,el3) ,torch.mul(el3_conv,el4)]\n",
    "#         return skip_new\n",
    "#     def forward(self,x):\n",
    "#         return self.add_skip(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haZAR\\anaconda3\\envs\\pytorchgpu\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNET(\n",
      "  (ups): ModuleList(\n",
      "    (0): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): DoubleConv(\n",
      "      (relusig): ReluSIG(\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReluSIG(\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReluSIG(\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (3): DoubleConv(\n",
      "      (relusig): ReluSIG(\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReluSIG(\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReluSIG(\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (5): DoubleConv(\n",
      "      (relusig): ReluSIG(\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReluSIG(\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReluSIG(\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (7): DoubleConv(\n",
      "      (relusig): ReluSIG(\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReluSIG(\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReluSIG(\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (downs): ModuleList(\n",
      "    (0): DoubleConv(\n",
      "      (relusig): ReluSIG(\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReluSIG(\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReluSIG(\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): DoubleConv(\n",
      "      (relusig): ReluSIG(\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReluSIG(\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReluSIG(\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): DoubleConv(\n",
      "      (relusig): ReluSIG(\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReluSIG(\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReluSIG(\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): DoubleConv(\n",
      "      (relusig): ReluSIG(\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReluSIG(\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReluSIG(\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (bottleneck): DoubleConv(\n",
      "    (relusig): ReluSIG(\n",
      "      (gelu): GELU(approximate='none')\n",
      "      (sigmoid): Sigmoid()\n",
      "    )\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReluSIG(\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReluSIG(\n",
      "        (gelu): GELU(approximate='none')\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_conv): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class ReluSIG(nn.Module):\n",
    "    def __init__(self , embedding_dim):\n",
    "        super().__init__()\n",
    "        self.gelu = nn.GELU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        Relumoid = self.gelu(x)*self.sigmoid(torch.square(x))\n",
    "        return Relumoid\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.relusig = ReluSIG(out_channels)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            self.relusig,\n",
    "            nn.Conv2d(out_channels,out_channels, 3, 1, 1,bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            self.relusig,\n",
    "            \n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.conv(x)\n",
    "class UNET(nn.Module):\n",
    "    def __init__(\n",
    "            self , in_channels=3, out_channels=1 , features=[64,128,256,512],\n",
    "    ):\n",
    "        super(UNET , self).__init__()\n",
    "        self.ups = nn.ModuleList() #list\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2 , stride=2)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(in_channels,feature))\n",
    "            in_channels = feature\n",
    "        \n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(\n",
    "                nn.ConvTranspose2d(\n",
    "                    feature*2 , feature , kernel_size = 2 , stride = 2,\n",
    "                )\n",
    "            )\n",
    "            self.ups.append(DoubleConv(feature*2,feature))\n",
    "\n",
    "        self.bottleneck = DoubleConv(features[-1],features[-1]*2)\n",
    "        self.final_conv = nn.Conv2d(features[0],out_channels,kernel_size=1)\n",
    "        self.add_skip = ListSkip()\n",
    "    def forward(self,x):\n",
    "        skip_connections = []\n",
    "        for i,down in enumerate(self.downs):\n",
    "            x = down(x)\n",
    "            \n",
    "            skip_connections.append(x) ##adding of previsous layer slip connections\n",
    "            x = self.pool(x)\n",
    "        x = self.bottleneck(x)\n",
    "        # skip_connections_new = self.add_skip(skip_connections)\n",
    "        skip_connections_new = self.add_skip(skip_connections)\n",
    "\n",
    "\n",
    "\n",
    "        skip_connections = skip_connections_new[::-1]\n",
    "\n",
    "        for idx in range(0,len(self.ups),2):\n",
    "            x = self.ups[idx](x)\n",
    "            skip_connection = skip_connections[idx//2]\n",
    "            \n",
    "            if x.shape != skip_connection.shape:\n",
    "                x = TF.resize(x,size=skip_connection.shape[2:])\n",
    "\n",
    "            concat_skip = torch.cat((skip_connection,x),dim=1)\n",
    "\n",
    "            x= self.ups[idx+1](concat_skip)\n",
    "            \n",
    "\n",
    "        return self.sigmoid(self.final_conv(x))\n",
    "\n",
    "\n",
    "        \n",
    "def load_model(model_name):\n",
    "    if model_name == 'UNet':\n",
    "        model = UNET(in_channels=3, out_channels=4)\n",
    "    else:\n",
    "        raise ValueError('Please input valid model name, {} not in model zones.'.format(model_name))\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = load_model(model_name='UNet')\n",
    "    print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
