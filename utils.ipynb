{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "%run dataset.ipynb\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state , filename=\"my_checkpointm2.pth.tar\"):\n",
    "    print(\"Saving checkpoint\")\n",
    "    torch.save(state,filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint , model):\n",
    "    print(\"loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(\n",
    "        train_dir,\n",
    "        csv_file_path,\n",
    "        val_dir,\n",
    "        val_csv_file_path,\n",
    "        batch_size,\n",
    "        train_transform,\n",
    "        val_transform,\n",
    "        num_workers = 0,\n",
    "        pin_memory = True,\n",
    "):\n",
    "    train_ds = CephXrayDataset(\n",
    "        csv_file_path = csv_file_path,\n",
    "        image_path =train_dir,\n",
    "        transform = train_transform,\n",
    "        )\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size = batch_size,\n",
    "        num_workers = num_workers,\n",
    "        pin_memory = pin_memory,\n",
    "        shuffle = True,\n",
    "    )\n",
    "\n",
    "    val_ds= CephXrayDataset(\n",
    "        csv_file_path = val_csv_file_path,\n",
    "        image_path =val_dir,\n",
    "        transform =val_transform,\n",
    "\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        shuffle = False,\n",
    "\n",
    "    )\n",
    "\n",
    "    return train_loader , val_loader\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader , model ,loss_fn ,device = \"cuda\"):\n",
    "    model.eval()\n",
    "    valid_losses=[]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (image,heatmap)in loader:\n",
    "            image, heatmap = image.float().to(device = device), heatmap.float().to(device = device)\n",
    "            output = model(image)\n",
    "            loss = loss_fn(output,heatmap)\n",
    "            valid_losses.append(loss.item())\n",
    "        valid_loss = np.mean(valid_losses)\n",
    "        print('Validation loss: {:.6f}'.format(valid_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- def save_predictions_as_imgs(\n",
    "    loader, model, folder=\"saved_images/\", device=\"cuda\"\n",
    "):\n",
    "    model.eval()\n",
    "    for idx, (image, heatmap) in enumerate(loader):\n",
    "        image, heatmap = image.float().to(device = device), heatmap.float().to(device = device)\n",
    "        with torch.no_grad():\n",
    "            preds = model(image)a\n",
    "\n",
    "# Save the predictions\n",
    "            heatmap_sum = heatmap.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Now the heatmap has the same number of channels as the image and they can be combined\n",
    "            imposed_image = image + heatmap_sum\n",
    "\n",
    "            preds_sum = preds.sum(axis=1, keepdims=True)\n",
    "            imposed_image_preds = image + preds_sum\n",
    "            torchvision.utils.save_image(imposed_image_preds, f\"{folder}/imposed_preds_{idx}.png\")\n",
    "            \n",
    "                \n",
    "            torchvision.utils.save_image(imposed_image, f\"{folder}{idx}.png\")\n",
    "         -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions_as_imgs(\n",
    "    loader, model, folder=\"saved_images/\", device=\"cuda\"\n",
    "):\n",
    "    num_correct= []\n",
    "    num_pixels = []\n",
    "    model.eval()\n",
    "    for idx, (image, heatmap) in enumerate(loader):\n",
    "        image, heatmap = image.float().to(device = device), heatmap.float().to(device = device)\n",
    "        with torch.no_grad():\n",
    "            preds = model(image)\n",
    "            predss = (preds> 0.5).float()\n",
    "            coords = torch.nonzero(predss)\n",
    "            print(f\"Coordinates of predicted pixels: {coords}\")\n",
    "\n",
    "            heatmap_sum = heatmap.sum(axis=1, keepdims=True)\n",
    "\n",
    "            imposed_image = image + heatmap_sum\n",
    "\n",
    "            preds_sum = preds.sum(axis=1, keepdims=True)\n",
    "            imposed_image_preds = image + preds_sum\n",
    "            torchvision.utils.save_image(imposed_image_preds, f\"{folder}/imposed_preds_{idx}.png\")\n",
    "            \n",
    "                \n",
    "            torchvision.utils.save_image(imposed_image, f\"{folder}/imposed_actual_{idx}.png\")\n",
    "            # torchvision.utils.save_image(image_with_clusters, f\"{folder}{idx}.png\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
